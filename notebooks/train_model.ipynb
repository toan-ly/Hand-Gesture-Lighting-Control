{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peH2PV9gn1cv",
        "outputId": "d3774d73-0a24-437a-9199-d24d13e0892f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L9QZbsqlXKvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77fb0e6-f6b5-446d-d02f-39489a5bc051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data/’: File exists\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gzWOtABiVmJ38usCSDe5F9gR2tECt3zu\n",
            "To: /content/data/landmark_val.csv\n",
            "100% 369k/369k [00:00<00:00, 91.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nIo1_wBmkovz-u_BCsV5c1Kbz6ZqoKwq\n",
            "To: /content/data/landmark_test.csv\n",
            "100% 320k/320k [00:00<00:00, 61.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZteHYSgbuZu_GcUJHW8ZzoZv1DE8-oLw\n",
            "To: /content/data/hand_gesture.yaml\n",
            "100% 120/120 [00:00<00:00, 679kB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir data/\n",
        "\n",
        "# connect drive\n",
        "\n",
        "!cp /content/drive/MyDrive/landmark_train.csv data\n",
        "!gdown  1gzWOtABiVmJ38usCSDe5F9gR2tECt3zu -O data/\n",
        "# !gdown  15lwipssmC_K82ukRfb0uVCiDH1TZ3QCf -O data/\n",
        "!gdown  1nIo1_wBmkovz-u_BCsV5c1Kbz6ZqoKwq -O data/\n",
        "# Download file hand_gesture.yaml\n",
        "!gdown  1ZteHYSgbuZu_GcUJHW8ZzoZv1DE8-oLw -O data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqhc2257_m3K",
        "outputId": "aa5f3579-7002-4eb3-df3e-2071123d7887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe==0.10.18 in /usr/local/lib/python3.10/dist-packages (0.10.18)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (4.25.5)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.18) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.18) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.18) (1.16.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe==0.10.18\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xZPTB4Gm_8KF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import yaml\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "import mediapipe as mp\n",
        "from torch import optim\n",
        "from datetime import datetime\n",
        "from torchmetrics import Accuracy\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DQH1LReLB03s"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, filepath):\n",
        "        self.data = pd.read_csv(filepath)\n",
        "        self.labels = torch.from_numpy(self.data.iloc[:, 0].to_numpy())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        one_hot_label = self.labels[idx]\n",
        "        torch_data = torch.from_numpy(self.data.iloc[idx, 1:].to_numpy(dtype=np.float32))\n",
        "        return torch_data, one_hot_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qdI0AaZt_38Q"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim=63, hidden_dim=128):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        list_label = label_dict_from_config_file(\"./data/hand_gesture.yaml\")\n",
        "        self.output_dim = len(list_label)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            # Layer 1\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            # Layer 2\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            # Layer 3\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            # Layer 4\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.6),\n",
        "            # Output layer\n",
        "            nn.Linear(hidden_dim, self.output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        return self.model(x)\n",
        "\n",
        "    def predict(self, x, threshold=0.8):\n",
        "        logits = self(x)\n",
        "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
        "        chosen_ind = torch.argmax(softmax_prob, dim=1)\n",
        "        return torch.where(softmax_prob[0, chosen_ind] > threshold, chosen_ind, -1)\n",
        "\n",
        "    def predict_with_known_class(self, x):\n",
        "        logits = self(x)\n",
        "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
        "        return torch.argmax(softmax_prob, dim=1)\n",
        "\n",
        "    def score(self, logits):\n",
        "        return -torch.amax(logits, dim=1)\n",
        "\n",
        "\n",
        "def label_dict_from_config_file(relative_path):\n",
        "    with open(relative_path, \"r\") as f:\n",
        "        label_tag = yaml.full_load(f)[\"gestures\"]\n",
        "    return label_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h9prQCqNTXPS"
      },
      "outputs": [],
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.watched_metrics = np.inf\n",
        "\n",
        "    def early_stop(self, current_value):\n",
        "        if current_value < self.watched_metrics:\n",
        "            self.watched_metrics = current_value\n",
        "            self.counter = 0\n",
        "        elif current_value > (self.watched_metrics + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JeQ4bVtke_Se"
      },
      "outputs": [],
      "source": [
        "class HandLandmarksDetector():\n",
        "    def __init__(self) -> None:\n",
        "        self.mp_drawing = mp.solutions.drawing_utils\n",
        "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
        "        self.mp_hands = mp.solutions.hands\n",
        "        self.detector = self.mp_hands.Hands(\n",
        "            static_image_mode=False,\n",
        "            max_num_hands=1,\n",
        "            min_detection_confidence=0.5\n",
        "        )\n",
        "\n",
        "    def detectHand(self, frame):\n",
        "        \"\"\"\n",
        "        Detects the hand landmarks in the frame and returns\n",
        "        the landmarks along with an annotated image.\n",
        "        \"\"\"\n",
        "        hands = []\n",
        "        frame = cv2.flip(frame, 1)\n",
        "        annotated_image = frame.copy()\n",
        "        results = self.detector.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        if results.multi_hand_landmarks is not None:\n",
        "            for hand_landmarks in results.multi_hand_landmarks:\n",
        "                hand = []\n",
        "                self.mp_drawing.draw_landmarks(\n",
        "                    annotated_image,\n",
        "                    hand_landmarks,\n",
        "                    self.mp_hands.HAND_CONNECTIONS,\n",
        "                    self.mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                    self.mp_drawing_styles.get_default_hand_connections_style())\n",
        "                for landmark in hand_landmarks.landmark:\n",
        "                    x, y, z = landmark.x, landmark.y, landmark.z\n",
        "                    hand.extend([x, y, z])\n",
        "            hands.append(hand)\n",
        "        return hands, annotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fPBj338O_tcY"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, val_loader, model, criterion, early_stopper, optimizer, epochs=300):\n",
        "    # add auroc score\n",
        "    best_vloss = 1_000_000\n",
        "    timestamp = datetime.now().strftime('%d-%m %H:%M')\n",
        "    for epoch in range(epochs):\n",
        "        # training\n",
        "        model.train(True)\n",
        "        running_loss = 0.0\n",
        "        acc_train = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
        "        for batch_idx, data in enumerate(train_loader):\n",
        "            inputs, labels = data\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(inputs)\n",
        "            loss = criterion(preds, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            acc_train.update(model.predict_with_known_class(inputs), labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # validation\n",
        "        model.train(False)\n",
        "        running_vloss = 0.0\n",
        "        acc_val = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
        "        for i, vdata in enumerate(val_loader):\n",
        "            vinputs, vlabels = vdata\n",
        "            preds = model(vinputs)\n",
        "            vloss = criterion(preds, vlabels)\n",
        "            running_vloss += vloss.item()\n",
        "            acc_val.update(model.predict_with_known_class(vinputs), vlabels)\n",
        "\n",
        "        # Log the running loss averaged per batch for both training and validation\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}]: \")\n",
        "        print(f\"\\ttrain_acc: {acc_train.compute().item()}, val_acc: {acc_val.compute().item()}\")\n",
        "        avg_vloss = running_vloss / len(val_loader)\n",
        "        print(f'\\ttrain_loss: {avg_loss}, val_loss: {avg_vloss}')\n",
        "\n",
        "        # Track best performance, and save the model's state\n",
        "        if avg_vloss < best_vloss:\n",
        "            best_vloss = avg_vloss\n",
        "            best_model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_best'\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "\n",
        "        if early_stopper.early_stop(avg_vloss):\n",
        "            print(f'Stopping at epoch {epoch+1}, minimum: {early_stopper.watched_metrics}')\n",
        "            break\n",
        "\n",
        "    model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_last'\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print(acc_val.compute())\n",
        "    return model, best_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MhE1acacBG8z"
      },
      "outputs": [],
      "source": [
        "DATA_FOLDER_PATH = \"./data/\"\n",
        "LIST_LABEL = label_dict_from_config_file(\"./data/hand_gesture.yaml\")\n",
        "\n",
        "train_path = os.path.join(DATA_FOLDER_PATH, \"landmark_train.csv\")\n",
        "val_path = os.path.join(DATA_FOLDER_PATH, \"landmark_val.csv\")\n",
        "test_path = os.path.join(DATA_FOLDER_PATH, \"landmark_test.csv\")\n",
        "save_path = './models'\n",
        "os.makedirs(save_path,exist_ok=True)\n",
        "\n",
        "train_set = CustomImageDataset(train_path)\n",
        "train_loader = DataLoader(train_set, batch_size=40, shuffle=True)\n",
        "\n",
        "val_set = CustomImageDataset(val_path)\n",
        "val_loader = DataLoader(val_set, batch_size=50, shuffle=False)\n",
        "\n",
        "test_set = CustomImageDataset(test_path)\n",
        "test_loader = DataLoader(test_set, batch_size=20, shuffle=False)\n",
        "\n",
        "model = NeuralNetwork()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "early_stopper = EarlyStopper(patience=30, min_delta=0.01)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKCBHUBFe_Sf",
        "outputId": "83842d82-0139-45a5-9aad-b4135df7b06a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/300]: \n",
            "\ttrain_acc: 0.246257483959198, val_acc: 0.34812286496162415\n",
            "\ttrain_loss: 1.6001512701831646, val_loss: 1.5891388654708862\n",
            "Epoch [2/300]: \n",
            "\ttrain_acc: 0.397455096244812, val_acc: 0.35494881868362427\n",
            "\ttrain_loss: 1.552045699375779, val_loss: 1.5426491300264995\n",
            "Epoch [3/300]: \n",
            "\ttrain_acc: 0.5071107745170593, val_acc: 0.41296929121017456\n",
            "\ttrain_loss: 1.4377595559874576, val_loss: 1.4003636240959167\n",
            "Epoch [4/300]: \n",
            "\ttrain_acc: 0.6253742575645447, val_acc: 0.552901029586792\n",
            "\ttrain_loss: 1.1840336509604952, val_loss: 1.0669372876485188\n",
            "Epoch [5/300]: \n",
            "\ttrain_acc: 0.7529940009117126, val_acc: 0.788395881652832\n",
            "\ttrain_loss: 0.8167673731917766, val_loss: 0.647696519891421\n",
            "Epoch [6/300]: \n",
            "\ttrain_acc: 0.8259730339050293, val_acc: 0.8976109027862549\n",
            "\ttrain_loss: 0.550378443589851, val_loss: 0.39768968025843304\n",
            "Epoch [7/300]: \n",
            "\ttrain_acc: 0.908682644367218, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.3653398723299824, val_loss: 0.19972985113660494\n",
            "Epoch [8/300]: \n",
            "\ttrain_acc: 0.9472305178642273, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.24941616249618245, val_loss: 0.10217899433337152\n",
            "Epoch [9/300]: \n",
            "\ttrain_acc: 0.966317355632782, val_acc: 0.9726962447166443\n",
            "\ttrain_loss: 0.18810805467082492, val_loss: 0.07241223061767717\n",
            "Epoch [10/300]: \n",
            "\ttrain_acc: 0.972305417060852, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.15084238444913678, val_loss: 0.04717279667966068\n",
            "Epoch [11/300]: \n",
            "\ttrain_acc: 0.9708083868026733, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.11440991540786935, val_loss: 0.04010303706551591\n",
            "Epoch [12/300]: \n",
            "\ttrain_acc: 0.973802387714386, val_acc: 0.9931740760803223\n",
            "\ttrain_loss: 0.10754165442577049, val_loss: 0.02788899642958616\n",
            "Epoch [13/300]: \n",
            "\ttrain_acc: 0.9752994179725647, val_acc: 0.9829351305961609\n",
            "\ttrain_loss: 0.10921672809479842, val_loss: 0.037649581664785124\n",
            "Epoch [14/300]: \n",
            "\ttrain_acc: 0.9816616773605347, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.0771740788955297, val_loss: 0.03014802303126392\n",
            "Epoch [15/300]: \n",
            "\ttrain_acc: 0.98128741979599, val_acc: 0.9829351305961609\n",
            "\ttrain_loss: 0.08178271463057443, val_loss: 0.048603059869492427\n",
            "Epoch [16/300]: \n",
            "\ttrain_acc: 0.9805389046669006, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.0728973032100432, val_loss: 0.028654531318655547\n",
            "Epoch [17/300]: \n",
            "\ttrain_acc: 0.9842814207077026, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.07273901561136122, val_loss: 0.04073239577216251\n",
            "Epoch [18/300]: \n",
            "\ttrain_acc: 0.983907163143158, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.06864178496232229, val_loss: 0.02564322242930454\n",
            "Epoch [19/300]: \n",
            "\ttrain_acc: 0.985029935836792, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.0568454652301856, val_loss: 0.028494031061806407\n",
            "Epoch [20/300]: \n",
            "\ttrain_acc: 0.9846556782722473, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.06338237437989507, val_loss: 0.0330393045587698\n",
            "Epoch [21/300]: \n",
            "\ttrain_acc: 0.98764967918396, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.06308071739943837, val_loss: 0.030516209687145118\n",
            "Epoch [22/300]: \n",
            "\ttrain_acc: 0.983907163143158, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.06164761244861493, val_loss: 0.03068828445005541\n",
            "Epoch [23/300]: \n",
            "\ttrain_acc: 0.9846556782722473, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.06798923427044455, val_loss: 0.03189204807010052\n",
            "Epoch [24/300]: \n",
            "\ttrain_acc: 0.985029935836792, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.05290874904855641, val_loss: 0.022945387772172882\n",
            "Epoch [25/300]: \n",
            "\ttrain_acc: 0.9869012236595154, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.051619599858271095, val_loss: 0.02476751885539367\n",
            "Epoch [26/300]: \n",
            "\ttrain_acc: 0.9854041934013367, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.045760512991405246, val_loss: 0.03541226036759326\n",
            "Epoch [27/300]: \n",
            "\ttrain_acc: 0.9891467094421387, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.05651897576693168, val_loss: 0.0304073209863418\n",
            "Epoch [28/300]: \n",
            "\ttrain_acc: 0.98764967918396, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.055516773396963946, val_loss: 0.02684414141185698\n",
            "Epoch [29/300]: \n",
            "\ttrain_acc: 0.9883981943130493, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.05050605156375512, val_loss: 0.04060928648990133\n",
            "Epoch [30/300]: \n",
            "\ttrain_acc: 0.983907163143158, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.04839674761317281, val_loss: 0.03471618987714464\n",
            "Epoch [31/300]: \n",
            "\ttrain_acc: 0.9895209670066833, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.043021953998328144, val_loss: 0.03100238146968574\n",
            "Epoch [32/300]: \n",
            "\ttrain_acc: 0.9921407103538513, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.04548096389739093, val_loss: 0.024928276707062953\n",
            "Epoch [33/300]: \n",
            "\ttrain_acc: 0.9906437397003174, val_acc: 0.9931740760803223\n",
            "\ttrain_loss: 0.03717898529843052, val_loss: 0.02834179896126443\n",
            "Epoch [34/300]: \n",
            "\ttrain_acc: 0.9883981943130493, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.043268948710009233, val_loss: 0.0202578894780648\n",
            "Epoch [35/300]: \n",
            "\ttrain_acc: 0.9880239367485046, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.04767075485424764, val_loss: 0.03328129744962401\n",
            "Epoch [36/300]: \n",
            "\ttrain_acc: 0.989895224571228, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.03951565011877066, val_loss: 0.02515910099100438\n",
            "Epoch [37/300]: \n",
            "\ttrain_acc: 0.9883981943130493, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.0444102409059432, val_loss: 0.03567622704895257\n",
            "Epoch [38/300]: \n",
            "\ttrain_acc: 0.9869012236595154, val_acc: 0.9829351305961609\n",
            "\ttrain_loss: 0.036581698818994104, val_loss: 0.03812385985384026\n",
            "Epoch [39/300]: \n",
            "\ttrain_acc: 0.9906437397003174, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.047061309100253815, val_loss: 0.024160217210161743\n",
            "Epoch [40/300]: \n",
            "\ttrain_acc: 0.9917664527893066, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.03844672243055234, val_loss: 0.03095139084211951\n",
            "Epoch [41/300]: \n",
            "\ttrain_acc: 0.9910179376602173, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.03403016589425588, val_loss: 0.040782357930841805\n",
            "Epoch [42/300]: \n",
            "\ttrain_acc: 0.9895209670066833, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.04547701028884569, val_loss: 0.044745307904274036\n",
            "Epoch [43/300]: \n",
            "\ttrain_acc: 0.988772451877594, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.03875371999517361, val_loss: 0.03496392539348866\n",
            "Epoch [44/300]: \n",
            "\ttrain_acc: 0.9932634830474854, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.02957479126139808, val_loss: 0.026888261760025973\n",
            "Epoch [45/300]: \n",
            "\ttrain_acc: 0.9910179376602173, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.03290221016721995, val_loss: 0.03384667099029078\n",
            "Epoch [46/300]: \n",
            "\ttrain_acc: 0.9932634830474854, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.0327020632207338, val_loss: 0.030045462131359574\n",
            "Epoch [47/300]: \n",
            "\ttrain_acc: 0.99363774061203, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.03688389415602519, val_loss: 0.03522603579934488\n",
            "Epoch [48/300]: \n",
            "\ttrain_acc: 0.992514967918396, val_acc: 0.9829351305961609\n",
            "\ttrain_loss: 0.03155637967379402, val_loss: 0.052131755673978354\n",
            "Epoch [49/300]: \n",
            "\ttrain_acc: 0.9917664527893066, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.03233637234870233, val_loss: 0.026987848153945986\n",
            "Epoch [50/300]: \n",
            "\ttrain_acc: 0.989895224571228, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.03821137468608569, val_loss: 0.02824225941193011\n",
            "Epoch [51/300]: \n",
            "\ttrain_acc: 0.992514967918396, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.02407868687626419, val_loss: 0.032870003034759065\n",
            "Epoch [52/300]: \n",
            "\ttrain_acc: 0.9891467094421387, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.03495952521568971, val_loss: 0.02122243717728149\n",
            "Epoch [53/300]: \n",
            "\ttrain_acc: 0.991392195224762, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.0493148430702346, val_loss: 0.02521620734618561\n",
            "Epoch [54/300]: \n",
            "\ttrain_acc: 0.9917664527893066, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.029464737008284055, val_loss: 0.024310114833800373\n",
            "Epoch [55/300]: \n",
            "\ttrain_acc: 0.9910179376602173, val_acc: 0.9931740760803223\n",
            "\ttrain_loss: 0.030573141752436424, val_loss: 0.0296244829682261\n",
            "Epoch [56/300]: \n",
            "\ttrain_acc: 0.9906437397003174, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.024586041716844843, val_loss: 0.03772730455640764\n",
            "Epoch [57/300]: \n",
            "\ttrain_acc: 0.992514967918396, val_acc: 0.9931740760803223\n",
            "\ttrain_loss: 0.03295091326989637, val_loss: 0.023903709960829172\n",
            "Epoch [58/300]: \n",
            "\ttrain_acc: 0.9928892254829407, val_acc: 0.9829351305961609\n",
            "\ttrain_loss: 0.025573701759341604, val_loss: 0.04908682138602671\n",
            "Epoch [59/300]: \n",
            "\ttrain_acc: 0.992514967918396, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.027431571916955066, val_loss: 0.023358910263349724\n",
            "Epoch [60/300]: \n",
            "\ttrain_acc: 0.9906437397003174, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.0326969410612512, val_loss: 0.03587316622929393\n",
            "Epoch [61/300]: \n",
            "\ttrain_acc: 0.992514967918396, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.02786573832124861, val_loss: 0.03351731962902704\n",
            "Epoch [62/300]: \n",
            "\ttrain_acc: 0.992514967918396, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.03570455465806342, val_loss: 0.020093756849898153\n",
            "Epoch [63/300]: \n",
            "\ttrain_acc: 0.989895224571228, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.03500326507578868, val_loss: 0.019048357311172975\n",
            "Epoch [64/300]: \n",
            "\ttrain_acc: 0.9921407103538513, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.027671425736252107, val_loss: 0.03037839505388244\n",
            "Epoch [65/300]: \n",
            "\ttrain_acc: 0.9917664527893066, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.025970143132231463, val_loss: 0.04130333339386046\n",
            "Epoch [66/300]: \n",
            "\ttrain_acc: 0.991392195224762, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.024069746674747386, val_loss: 0.027980732978297358\n",
            "Epoch [67/300]: \n",
            "\ttrain_acc: 0.992514967918396, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.02813311264964877, val_loss: 0.037017729873847806\n",
            "Epoch [68/300]: \n",
            "\ttrain_acc: 0.99363774061203, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.02989607947398978, val_loss: 0.04959000019755422\n",
            "Epoch [69/300]: \n",
            "\ttrain_acc: 0.9921407103538513, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.02297668592872293, val_loss: 0.037522650687454494\n",
            "Epoch [70/300]: \n",
            "\ttrain_acc: 0.9940119981765747, val_acc: 0.9931740760803223\n",
            "\ttrain_loss: 0.02406982285901904, val_loss: 0.026479008434004452\n",
            "Epoch [71/300]: \n",
            "\ttrain_acc: 0.995134711265564, val_acc: 0.9931740760803223\n",
            "\ttrain_loss: 0.021035590049212995, val_loss: 0.03212704753377693\n",
            "Epoch [72/300]: \n",
            "\ttrain_acc: 0.9921407103538513, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.03249479753118175, val_loss: 0.027603394027134225\n",
            "Epoch [73/300]: \n",
            "\ttrain_acc: 0.995134711265564, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.022182948436455997, val_loss: 0.025049475388868814\n",
            "Epoch [74/300]: \n",
            "\ttrain_acc: 0.9940119981765747, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.019486476436132258, val_loss: 0.032956220667870184\n",
            "Epoch [75/300]: \n",
            "\ttrain_acc: 0.9928892254829407, val_acc: 0.9931740760803223\n",
            "\ttrain_loss: 0.028035040552130165, val_loss: 0.03467051138236835\n",
            "Epoch [76/300]: \n",
            "\ttrain_acc: 0.99363774061203, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.032365194313339334, val_loss: 0.03548717568151005\n",
            "Epoch [77/300]: \n",
            "\ttrain_acc: 0.992514967918396, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.03041976691595515, val_loss: 0.02756384721002784\n",
            "Epoch [78/300]: \n",
            "\ttrain_acc: 0.995134711265564, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.024421650647018938, val_loss: 0.049321738037027295\n",
            "Epoch [79/300]: \n",
            "\ttrain_acc: 0.9928892254829407, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.02519357726829293, val_loss: 0.04421612555531359\n",
            "Epoch [80/300]: \n",
            "\ttrain_acc: 0.995134711265564, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.023133409471049516, val_loss: 0.04673226949536987\n",
            "Epoch [81/300]: \n",
            "\ttrain_acc: 0.9940119981765747, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.026589856755836354, val_loss: 0.04516283047843217\n",
            "Epoch [82/300]: \n",
            "\ttrain_acc: 0.9943862557411194, val_acc: 0.9829351305961609\n",
            "\ttrain_loss: 0.019092625440550105, val_loss: 0.05287299098923389\n",
            "Epoch [83/300]: \n",
            "\ttrain_acc: 0.9940119981765747, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.02548611799164661, val_loss: 0.04395741486253731\n",
            "Epoch [84/300]: \n",
            "\ttrain_acc: 0.9947604537010193, val_acc: 0.9931740760803223\n",
            "\ttrain_loss: 0.01947221728458778, val_loss: 0.03776690102013921\n",
            "Epoch [85/300]: \n",
            "\ttrain_acc: 0.9932634830474854, val_acc: 0.9931740760803223\n",
            "\ttrain_loss: 0.028090690930700626, val_loss: 0.023252921752828115\n",
            "Epoch [86/300]: \n",
            "\ttrain_acc: 0.9947604537010193, val_acc: 0.9931740760803223\n",
            "\ttrain_loss: 0.025405670928859165, val_loss: 0.025697321159062387\n",
            "Epoch [87/300]: \n",
            "\ttrain_acc: 0.9955089688301086, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.018555012394312714, val_loss: 0.041927521798243106\n",
            "Epoch [88/300]: \n",
            "\ttrain_acc: 0.9932634830474854, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.028477946018761913, val_loss: 0.0297457631173567\n",
            "Epoch [89/300]: \n",
            "\ttrain_acc: 0.9921407103538513, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.032056147511527223, val_loss: 0.03368011927614134\n",
            "Epoch [90/300]: \n",
            "\ttrain_acc: 0.996257483959198, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.022344613256655745, val_loss: 0.040194474760104036\n",
            "Epoch [91/300]: \n",
            "\ttrain_acc: 0.9970059990882874, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.022612660105944846, val_loss: 0.03897426028965848\n",
            "Epoch [92/300]: \n",
            "\ttrain_acc: 0.9943862557411194, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.014844977925879075, val_loss: 0.051429498406529696\n",
            "Epoch [93/300]: \n",
            "\ttrain_acc: 0.9966317415237427, val_acc: 0.9897611141204834\n",
            "\ttrain_loss: 0.014010304227165545, val_loss: 0.05033119360974799\n",
            "Epoch [94/300]: \n",
            "\ttrain_acc: 0.995134711265564, val_acc: 0.9829351305961609\n",
            "\ttrain_loss: 0.020626298314804878, val_loss: 0.04156234578336656\n",
            "Epoch [95/300]: \n",
            "\ttrain_acc: 0.9928892254829407, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.020142326237018733, val_loss: 0.05080603373354128\n",
            "Epoch [96/300]: \n",
            "\ttrain_acc: 0.9947604537010193, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.027129882145603534, val_loss: 0.04713631503543544\n",
            "Epoch [97/300]: \n",
            "\ttrain_acc: 0.9940119981765747, val_acc: 0.9829351305961609\n",
            "\ttrain_loss: 0.017189478439994767, val_loss: 0.04932815484441259\n",
            "Epoch [98/300]: \n",
            "\ttrain_acc: 0.9940119981765747, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.01652808984048289, val_loss: 0.03637679839437169\n",
            "Epoch [99/300]: \n",
            "\ttrain_acc: 0.9947604537010193, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.01819242189448056, val_loss: 0.04129764625818666\n",
            "Epoch [100/300]: \n",
            "\ttrain_acc: 0.9970059990882874, val_acc: 0.9863481521606445\n",
            "\ttrain_loss: 0.014223615482532934, val_loss: 0.04227992176951526\n",
            "Stopping at epoch 100, minimum: 0.019048357311172975\n",
            "tensor(0.9863)\n"
          ]
        }
      ],
      "source": [
        "model, best_model_path = train(train_loader, val_loader, model, criterion, early_stopper, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuKEiiC_BWDM",
        "outputId": "4a800870-2378-495a-db7d-946759155b89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork\n",
            "Accuracy of model: 0.9724409580230713\n",
            "========================================================================\n"
          ]
        }
      ],
      "source": [
        "network = NeuralNetwork()\n",
        "network.load_state_dict(torch.load(best_model_path, weights_only=False))\n",
        "\n",
        "network.eval()\n",
        "acc_test = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
        "for i, test_data in enumerate(test_loader):\n",
        "    test_input, test_label = test_data\n",
        "    preds = network(test_input)\n",
        "    acc_test.update(preds, test_label)\n",
        "\n",
        "print(network.__class__.__name__)\n",
        "print(f\"Accuracy of model: {acc_test.compute().item()}\")\n",
        "print(\"========================================================================\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}